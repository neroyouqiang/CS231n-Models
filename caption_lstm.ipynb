{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datasets import DataCocoFeat\n",
    "from models import LSTMCaption\n",
    "from optimers import OptimerAdam\n",
    "from utils import check_gradient, show_training_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (400135, 512)\n",
      "Training labels shape:  (400135, 17)\n",
      "Validation data shape:  (195954, 512)\n",
      "Validation labels shape:  (195954, 17)\n",
      "Number of training images:  82783\n",
      "Number of validation images:  40504\n",
      "Number of words:  1004\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataloader = DataCocoFeat('./datasets/coco_captioning/', pca_features=True)\n",
    "dataloader.show_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_model(hyperparams, device=''):\n",
    "    return LSTMCaption(dataloader.x_train.shape[1], None, hyperparams=hyperparams, seed=101, device=device)\n",
    "\n",
    "\n",
    "def test_model(model, data, idx_train, idx_val):\n",
    "    caps_train = model.predict(data.x_train[idx_train])\n",
    "    caps_val = model.predict(data.x_val[idx_val])\n",
    "\n",
    "    # the predicted captions\n",
    "    for i in range(len(caps_train)):\n",
    "        print('Predicted training data:', data.decode_captions(caps_train[i]))\n",
    "        data.show_by_index(idx_train[i], data_type='train')\n",
    "\n",
    "    for i in range(len(caps_val)):\n",
    "        print('Predicted validation data:', data.decode_captions(caps_val[i]))\n",
    "        data.show_by_index(idx_val[i], data_type='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check result:\n",
      "Init loss is \n",
      "[75.08026]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "model = get_init_model({'word_to_idx': dataloader.data['word_to_idx'],\n",
    "                        'reg': 0., 'num_hidden': 32, 'num_vector': 32, 'init_scale': None}, device='')\n",
    "\n",
    "# init loss\n",
    "loss = model.backward(dataloader.x_train[0: 100, :], dataloader.y_train[0: 100])\n",
    "print('Sanity check result:')\n",
    "print('Init loss is', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient check result -  1 :\n",
      "Layer | Key | Numerical gradient | Calculated gradient | Relative error\n",
      "<class 'models.layers.layers.Linear'> W 0.0078582763671875 0.007861453 0.0004041725154276654\n",
      "<class 'models.layers.layers.Linear'> b 0.01445770263671875 0.01446102 0.00022942721582602075\n",
      "<class 'models.layers.rnn_layers.WordEmbedding'> W_embed 0.0 0.0 0.0\n",
      "<class 'models.layers.rnn_layers.LSTM'> Wx 3.814697265625e-05 3.839045e-05 0.006362351745829909\n",
      "<class 'models.layers.rnn_layers.LSTM'> Wh 0.0006103515625 0.0006280303 0.02855131397354991\n",
      "<class 'models.layers.rnn_layers.LSTM'> b -0.0014495849609375 -0.0014397334 0.006819276285125429\n",
      "<class 'models.layers.rnn_layers.LinearForRNN'> W -0.00026702880859375 -0.0002672776 0.0009312242723149029\n",
      "<class 'models.layers.rnn_layers.LinearForRNN'> b 0.010833740234375 0.01081694 0.00155192609738076\n"
     ]
    }
   ],
   "source": [
    "# gradient check\n",
    "for i in range(1):\n",
    "    print('\\nGradient check result - ', i + 1, ':')\n",
    "    check_gradient(model, dataloader.x_train[0: 100, :], dataloader.y_train[0: 100], h=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load small dataset\n",
    "smallloader = DataCocoFeat('./datasets/coco_captioning/', pca_features=True,\n",
    "                           num_train=64, num_val=64, order_by='random')\n",
    "\n",
    "# init model\n",
    "model = get_init_model({'word_to_idx': dataloader.data['word_to_idx'],\n",
    "                        'reg': 0., 'num_hidden': 512, 'num_vector': 256})\n",
    "\n",
    "# train model\n",
    "optimer = OptimerAdam({'learn_rate': 5e-3, 'learn_rate_decay': 0.995, 'num_iters': 200, 'batch_size': 32}, \n",
    "                      print_every=10, check_val_acc=False, check_train_acc=False)\n",
    "\n",
    "optimer.train(model, smallloader)\n",
    "\n",
    "# save model\n",
    "model.save('./saves/LSTMCaption/model_small.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss curve\n",
    "show_training_info(optimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "model = LSTMCaption.load('./saves/LSTMCaption/model_small.pkl')\n",
    "\n",
    "# test model\n",
    "test_model(model, smallloader, [0, 1, 3], [0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run time test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run time for CPU model:\n",
      "Forward time: 1.3654310703277588\n",
      "    Input linear forward time: 0.00575709342956543\n",
      "    Word embedding forward time: 0.0016629695892333984\n",
      "    RNN forward time: 1.2377729415893555\n",
      "    Output linear forward time: 0.12023806571960449\n",
      "\n",
      "Backward time: 2.060302972793579\n",
      "    Loss calculate time: 0.06282210350036621\n",
      "    Output linear backward time: 0.17243194580078125\n",
      "    RNN backward time: 1.7108380794525146\n",
      "    Word embedding backward time: 0.10556697845458984\n",
      "    Input linear backward time: 0.008643865585327148\n",
      "\n",
      "Reg time: 0.015360116958618164\n",
      "\n",
      "Run time for GPU model:\n",
      "Forward time: 0.5149998664855957\n",
      "    Input linear forward time: 0.005795955657958984\n",
      "    Word embedding forward time: 0.00115203857421875\n",
      "    RNN forward time: 0.4602680206298828\n",
      "    Output linear forward time: 0.047783851623535156\n",
      "\n",
      "Backward time: 2.6620171070098877\n",
      "    Loss calculate time: 0.07166004180908203\n",
      "    Output linear backward time: 0.14072704315185547\n",
      "    RNN backward time: 2.3174049854278564\n",
      "    Word embedding backward time: 0.12516093254089355\n",
      "    Input linear backward time: 0.007064104080200195\n",
      "\n",
      "Reg time: 0.019008636474609375\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "hyperparam = {'word_to_idx': dataloader.data['word_to_idx'],\n",
    "              'reg': 0., 'num_hidden': 1024, 'num_vector': 512, 'init_scale': None}\n",
    "\n",
    "model1 = get_init_model(hyperparam, device='cpu')\n",
    "model2 = get_init_model(hyperparam, device='')\n",
    "\n",
    "# init loss\n",
    "print('\\nRun time for CPU model:')\n",
    "loss1 = model1.backward(dataloader.x_train[0: 128, :], dataloader.y_train[0: 128], print_time=True)\n",
    "print('\\nRun time for GPU model:')\n",
    "loss2 = model2.backward(dataloader.x_train[0: 128, :], dataloader.y_train[0: 128], print_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM-Caption model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "if True:\n",
    "    model = get_init_model({'word_to_idx': dataloader.data['word_to_idx'],\n",
    "                            'reg': 0.01, 'num_hidden': 1024, 'num_vector': 512})\n",
    "else:\n",
    "    model = LSTMCaption.load('./saves/LSTMCaption/model.pkl')\n",
    "\n",
    "# train model 'learn_rate': 2e-3\n",
    "optimer = OptimerAdam({'learn_rate': 2e-3, 'learn_rate_decay': 0.995, 'num_iters': 2000, 'batch_size': 256}, \n",
    "                      print_every=100, check_val_acc=False, check_train_acc=False)\n",
    "\n",
    "optimer.train(model, dataloader)\n",
    "\n",
    "# save model\n",
    "model.save('./saves/LSTMCaption/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss curve\n",
    "show_training_info(optimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "model = LSTMCaption.load('./saves/LSTMCaption/model.pkl')\n",
    "\n",
    "# test model\n",
    "test_model(model, dataloader, [0, 1, 4], [10, 11, 12, 13, 14, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
